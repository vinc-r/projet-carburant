{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "explo_données_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Tw5ZgD1ZT-M2"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmvJ8UqGZsDZgvJPkYouVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinc-r/projet-carburant/blob/master/explo_donn%C3%A9es_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFTACsaoh3u1",
        "colab_type": "text"
      },
      "source": [
        "# Études des pompes à essence en France\n",
        "Étude réalisée par Vincent Rosset, commencée le 12/03/2020\n",
        "\n",
        "Vincent.Rosset@polytech-lille.net\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2HuVc5HKbE9",
        "colab_type": "text"
      },
      "source": [
        "*sources : [https://www.prix-carburants.gouv.fr/rubrique/opendata/](https://www.prix-carburants.gouv.fr/rubrique/opendata/)*\n",
        "\n",
        "Le site gouvernemental des prix des carburants met à disposition de manière libre et gratuite (Open data) les données relatives aux prix des carburants. Ces données sont référencées sur la plate-forme des données publiques de l’État (www.data.gouv.fr) et sont fournies sous la \"[Licence ouverte / Open licence](https://wiki.data.gouv.fr/wiki/Licence_Ouverte_/_Open_Licence)\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okoQ2euzi3Ec",
        "colab_type": "text"
      },
      "source": [
        "## Première feuille : Conversion des xml en csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMQLa_rkO3d",
        "colab_type": "text"
      },
      "source": [
        "La première feuille lit l'ensemble des XML représentant les données étudiés de manière hierarchique et sauvegarde ces données avec le format CSV.\n",
        "La décompression de ces fichiers est réalisée manuellement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sg1MooKjSug",
        "colab_type": "text"
      },
      "source": [
        "### Préambule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw5ZgD1ZT-M2",
        "colab_type": "text"
      },
      "source": [
        "#### Fonctions utilitaires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ8823VblCdI",
        "colab_type": "text"
      },
      "source": [
        "Fonctions utilitaires personnalisées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7092enEieGBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Timer property decorator\n",
        "# to get execution time of a function \n",
        "def timer(func):\n",
        "    def f(*args, **kwargs):\n",
        "        before = time()\n",
        "        rv = func(*args, **kwargs)\n",
        "        after = time()\n",
        "        print('\\n\\t\\t>>>',func.__name__,'execution time:', \n",
        "              round(after - before, 4),'secs. <<<')\n",
        "        return rv\n",
        "    f.__name__ = func.__name__\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8f-VsGRR3W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_logging_level(log, log_level=\"INFO\"):\n",
        "    if log_level == \"DEBUG\":\n",
        "        log.basicConfig(level=log.DEBUG)\n",
        "    elif log_level == \"INFO\":\n",
        "        log.basicConfig(level=log.INFO)\n",
        "    elif log_level == \"WARNING\":\n",
        "        log.basicConfig(level=log.WARNING)\n",
        "    elif log_level == \"ERROR\":\n",
        "        log.basicConfig(level=log.ERROR)\n",
        "    elif log_level == \"CRITICAL\":\n",
        "        log.basicConfig(level=log.CRITICAL)\n",
        "    else:\n",
        "        log.basicConfig(level=log.NOTSET)\n",
        "    log.info(\" > log ready\")\n",
        "    log.debug(\" > log level debug\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv9ejrnEakNo",
        "colab_type": "text"
      },
      "source": [
        "#### Variables globales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urhh-pSGMG_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start year\n",
        "START_YEAR = 2007\n",
        "\n",
        "# End year\n",
        "END_YEAR = 2018\n",
        "\n",
        "BASE_URL = \"https://storage.googleapis.com/essence-dataset-eda/PrixCarburants_annuel_\"\n",
        "\n",
        "PATH_TO_CSV_FILES = \"tmp/\"\n",
        "\n",
        "# choose log level\n",
        "# Niveau : \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\n",
        "# Attention avant de choisir le niveau DEBUG\n",
        "#       cela génère de très importantes sorties\n",
        "LOG_LEVEL = \"INFO\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVydIuyqLAwX",
        "colab_type": "text"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "braIliuQLFCh",
        "colab_type": "code",
        "outputId": "6464deb2-99f4-4559-f34c-04fb5cf85351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import xml.sax\n",
        "from io import BytesIO, StringIO\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from time import time\n",
        "import os\n",
        "\n",
        "import logging as log\n",
        "set_logging_level(log, log_level=LOG_LEVEL)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root: > log ready\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6rIh9uFN86W",
        "colab_type": "text"
      },
      "source": [
        "## Lecture des fichiers zippés à partir de Google Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__QThfjQK7i-",
        "colab_type": "text"
      },
      "source": [
        "Fonctions pour aller lire les données à partir de l'URL renseigné."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTcj9_AJOBh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_datasets(year):\n",
        "        url = BASE_URL + str(year) + \".zip\"\n",
        "        r = requests.get(url)\n",
        "        return ZipFile(BytesIO(r.content))\n",
        "\n",
        "def generator_zip_file():\n",
        "    for year in range(START_YEAR,END_YEAR+1):\n",
        "        zip_ref = download_datasets(year)        \n",
        "        [xml_filename] = zip_ref.namelist()\n",
        "        yield (zip_ref.open(xml_filename),year)\n",
        "        zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y4QXSUQLKLa",
        "colab_type": "text"
      },
      "source": [
        "Création d'une classe à laquelle on apprend comment le jeu de données doit être lu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09yyyC8ZOP2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StreamHandler(xml.sax.handler.ContentHandler):\n",
        "\n",
        "    def __init__(self, year, pdv_csv, prix_csv, \n",
        "                 ouverture_csv, services_csv, \n",
        "                 fermeture_csv, rupture_csv):\n",
        "        # csv d'écriture\n",
        "        self.pdv_csv = pdv_csv\n",
        "        self.prix_csv = prix_csv\n",
        "        self.ouverture_csv = ouverture_csv\n",
        "        self.services_csv = services_csv\n",
        "        self.fermeture_csv = fermeture_csv\n",
        "        self.rupture_csv = rupture_csv\n",
        "        # dictionnaire de stockage des info pdv\n",
        "        self.found = {\n",
        "            \"pdv\" : {}, \"adresse\" : \"\", \"ville\" : \"\", \"ouverture\" : {},\n",
        "            \"jour\" : {}, \"horaire\" : {}, \"service\" : \"\",\n",
        "            \"prix\" : {}, \"fermeture\" : {}, \"rupture\" : {}\n",
        "        }\n",
        "        # tag actuel ouvert\n",
        "        self.actual_tag = None\n",
        "        # année en cours\n",
        "        self.year = year\n",
        "        log.info(\" > StreamHandler init > DONE\")\n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        \"\"\"\n",
        "        Appelé à chaque tag ouvrant, par exemple <coucou>. \n",
        "        Les attributs du tag sont disponibles sous forme de dictionnaire.\n",
        "        Ils sont stockés ensuite selon le nom du tag.\n",
        "        \"\"\"\n",
        "        # si le tag est reconnu => traitement\n",
        "        if name in self.found.keys():\n",
        "            # si le tag attend des attribus => stockage des attribus\n",
        "            if type(self.found[name]) == dict:\n",
        "                log.debug(\" > start tag > \" + name + \\\n",
        "                          \" : \" + str(dict(attrs.items())))\n",
        "                self.found[name] = dict(attrs.items())\n",
        "            else:\n",
        "                log.debug(\" > start tag > \" + name)\n",
        "            # MAJ tag actuel ouvert\n",
        "            self.actual_tag = name\n",
        "\n",
        "    def characters(self, content):\n",
        "        \"\"\"\n",
        "        Appelé à chaque texte entre les tags, par exemple pour \n",
        "        <coucou>ICI</coucou>AUSSI<tralala/> la méthode sera appelé \n",
        "        pour ICI puis pour AUSSI\n",
        "        \"\"\"\n",
        "        # concatenation de tous les eléments de text\n",
        "        # pour éviter les séparations indésirées des caratères spéciaux\n",
        "        if self.actual_tag is not None and \\\n",
        "        type(self.found[self.actual_tag]) == str:\n",
        "            self.found[self.actual_tag] += content\n",
        "            log.debug(\" > content : \" + self.found[self.actual_tag])\n",
        "        \n",
        "    def endElement(self, name):\n",
        "        \"\"\"\n",
        "        Appelé à chaque tag fermant, par exemple </coucou>\n",
        "        \"\"\"\n",
        "        # écriture des jours de services\n",
        "        if name == \"service\":\n",
        "            d = {\"id_pdv\" : self.found[\"pdv\"][\"id\"],\n",
        "                 \"year\" : self.year,\n",
        "                 \"service\" : self.found[name]}\n",
        "            log.debug(\" > write service row : \" + str(d))\n",
        "            self.services_csv.writerow(d)\n",
        "            self.found[name] = \"\"\n",
        "\n",
        "        # écriture des jours de fermeture\n",
        "        # format des jours d'ouverture pour années 2007 à 2017 inclu\n",
        "        elif name == \"ouverture\" and len(self.found[name]) > 0:\n",
        "            for day in [\"Lundi\", \"Mardi\", \"Mercredi\", \n",
        "                        \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]:\n",
        "                if day not in self.found[name]:\n",
        "                    d = {\"id_pdv\" : self.found[\"pdv\"][\"id\"],\n",
        "                         \"year\" : self.year,\n",
        "                         \"debut\" : self.found[name][\"debut\"],\n",
        "                         \"fin\" : self.found[name][\"fin\"],\n",
        "                         \"jour\" : day}\n",
        "                    log.debug(\" > write day on row : \" + str(d))\n",
        "                    self.ouverture_csv.writerow(d)\n",
        "\n",
        "        # nouveau format des ouverture à partir de 2018\n",
        "        # jour off non pris en compte car sans taf horaire\n",
        "        elif name == \"horaire\":\n",
        "            d = {\"id_pdv\" : self.found[\"pdv\"][\"id\"],\n",
        "                \"year\" : self.year,\n",
        "                \"debut\" : self.found[name][\"ouverture\"],\n",
        "                \"fin\" : self.found[name][\"fermeture\"],\n",
        "                \"jour\" : self.found[\"jour\"][\"nom\"]}\n",
        "            log.debug(\" > write day on row : \" + str(d))\n",
        "            self.ouverture_csv.writerow(d)\n",
        "            self.found[name] = {}\n",
        "\n",
        "        elif name == \"jour\":\n",
        "            # Uniquement RAZ du dictionnaire\n",
        "            # info déjà écrite avec horaire\n",
        "            # non RAZ avec horaire car il peut y avoir plusieurs horaire / jour\n",
        "            self.found[name] = {}\n",
        "\n",
        "        # type d'écriture identique sur les fichiers suivant\n",
        "        # => simplification code par boucle\n",
        "        # écriture des prix, fermeture, rupture\n",
        "        for f, n in ([self.prix_csv, \"prix\"],\n",
        "                     [self.fermeture_csv, \"fermeture\"],\n",
        "                     [self.rupture_csv, \"rupture\"]):\n",
        "            if name == n and len(self.found[name]) > 0:\n",
        "                self.found[n].update({\n",
        "                    \"id_pdv\" : self.found[\"pdv\"][\"id\"],\n",
        "                    \"year\" : self.year})\n",
        "                log.debug(\" > write \" + n + \" row : \" + str(self.found[n]))\n",
        "                f.writerow(self.found[n])\n",
        "                self.found[n] = {}\n",
        "\n",
        "        # si c'est une balise pdv qui est fermée,\n",
        "        # RAZ dictionnaire et écriture pdv\n",
        "        if name == \"pdv\":\n",
        "            log.debug(\" > write pdv row : \" + str(self.found[\"ouverture\"]))\n",
        "            self.found[\"pdv\"].update({\n",
        "                \"year\" : self.year,\n",
        "                \"adresse\": self.found[\"adresse\"],\n",
        "                \"ville\" : self.found[\"ville\"]\n",
        "            })\n",
        "            log.debug(\" > write pdv row : \" + str(self.found[\"pdv\"]))\n",
        "            self.pdv_csv.writerow(self.found[\"pdv\"])\n",
        "            # RAZ du dictionnaire de stockage\n",
        "            self.found = {\n",
        "                \"pdv\" : {}, \"adresse\" : \"\", \"ville\" : \"\", \"ouverture\" : {},\n",
        "                \"jour\" : {}, \"horaire\" : {}, \"service\" : \"\",\n",
        "                \"prix\" : {}, \"fermeture\" : {}, \"rupture\" : {}\n",
        "            }\n",
        "            log.debug(\" > RAZ found elements\")\n",
        "        # RAZ du tag\n",
        "        self.actual_tag = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys1Q9DZBLS90",
        "colab_type": "text"
      },
      "source": [
        "Fonction d'ouvertue d'un fichier csv pour écriture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO57A7HcO0TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def open_csv(csv_name, fnames):\n",
        "    f = open(csv_name, 'w', encoding='utf-8')\n",
        "    file_csv = csv.DictWriter(f, fieldnames=fnames)\n",
        "    file_csv.writeheader()\n",
        "    log.info(\" > File : \" + f.name + \" > OPEN\")\n",
        "    return file_csv, f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18sZu4P0LepE",
        "colab_type": "text"
      },
      "source": [
        "Fonction principale :\n",
        "1.   Ouverture des cvs\n",
        "2.   création du parser et du handler\n",
        "3.   parcours des xml sur toutes les années\n",
        "4.   écriture ligne par ligne dans les csv\n",
        "5.   fermeture des csv\n",
        "\n",
        "\n",
        "\n",
        "La propriété *@timer* permet d'afficher la durée d'exécution de la fonction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_wiHBRbN8l_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@timer\n",
        "def export_xml_to_csv():\n",
        "\n",
        "    # création dossier tmp où seront stockés les csv\n",
        "    if not os.path.exists(PATH_TO_CSV_FILES):\n",
        "        os.makedirs(PATH_TO_CSV_FILES)\n",
        "        log.info(\" > Folder : \" + PATH_TO_CSV_FILES + \" > CREATED\")\n",
        "\n",
        "    # ouverture des csv\n",
        "    pdv_csv, pdv_f = open_csv(PATH_TO_CSV_FILES + \"pdv.csv\", \n",
        "                            ['id', 'year', 'latitude', 'longitude', 'cp', \n",
        "                            'pop', 'adresse', 'ville'])\n",
        "\n",
        "    prix_csv, prix_f = open_csv(PATH_TO_CSV_FILES + \"prix.csv\", \n",
        "                                ['id_pdv', 'year', 'nom', \n",
        "                                 'id', 'maj', 'valeur'])\n",
        "\n",
        "    ouverture_csv, ouverture_f = open_csv(PATH_TO_CSV_FILES + \"ouverture.csv\", \n",
        "                                          ['id_pdv', 'year', \n",
        "                                           'jour', 'debut', 'fin'])\n",
        "\n",
        "    services_csv, services_f = open_csv(PATH_TO_CSV_FILES + \"services.csv\", \n",
        "                                        ['id_pdv', 'year', 'service'])\n",
        "\n",
        "    fermeture_csv, fermeture_f = open_csv(PATH_TO_CSV_FILES + \"fermeture.csv\",\n",
        "                                        ['id_pdv', 'year', \n",
        "                                        'type', \"debut\", \"fin\"])\n",
        "\n",
        "    rupture_csv, rupture_f = open_csv(PATH_TO_CSV_FILES + \"rupture.csv\",\n",
        "                                    ['id_pdv', 'year', \n",
        "                                    'id', \"nom\", \"debut\", \"fin\"])\n",
        "\n",
        "    parser = xml.sax.make_parser()\n",
        "    handler = StreamHandler(START_YEAR, pdv_csv, prix_csv, ouverture_csv,\n",
        "                            services_csv, fermeture_csv, rupture_csv)\n",
        "    log.info(\" > Handler > READY\")\n",
        "    parser.setContentHandler(handler)\n",
        "    log.info(\" > Parser > READY\")\n",
        "\n",
        "    for file,year in generator_zip_file():\n",
        "        log.info(\" > Year : \" + str(year) + \" > file found : \" + str(file))\n",
        "        # MAJ year sur handler\n",
        "        handler.year = year\n",
        "        # lecture xml\n",
        "        my_xml = StringIO(file.read().decode(\"utf-8\"))\n",
        "        # perser xml\n",
        "        parser.parse(my_xml)\n",
        "        # fermer fichier de lecture\n",
        "        file.close()\n",
        "        log.info(\" > Year : \" + str(year) + \" > DONE\")\n",
        "\n",
        "    # fermeture de tous les fichiers d'écriture\n",
        "    for f in [pdv_f, prix_f, ouverture_f, services_f, fermeture_f, rupture_f]:\n",
        "        f.close()\n",
        "        log.info(\" > File : \" + f.name + \" > CLOSE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bSnbP7sMkty",
        "colab_type": "text"
      },
      "source": [
        "Appel fonction principale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSdps1uaHjH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "8b8e4fe4-1acc-4eab-ac0d-25df785924f5"
      },
      "source": [
        "export_xml_to_csv()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root: > File : tmp/pdv.csv > OPEN\n",
            "INFO:root: > File : tmp/prix.csv > OPEN\n",
            "INFO:root: > File : tmp/ouverture.csv > OPEN\n",
            "INFO:root: > File : tmp/services.csv > OPEN\n",
            "INFO:root: > File : tmp/fermeture.csv > OPEN\n",
            "INFO:root: > File : tmp/rupture.csv > OPEN\n",
            "INFO:root: > StreamHandler init done\n",
            "INFO:root: > Handler > READY\n",
            "INFO:root: > Parser > READY\n",
            "INFO:root: > Year : 2007 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2007.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2007 > DONE\n",
            "INFO:root: > Year : 2008 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2008.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2008 > DONE\n",
            "INFO:root: > Year : 2009 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2009.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2009 > DONE\n",
            "INFO:root: > Year : 2010 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2010.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2010 > DONE\n",
            "INFO:root: > Year : 2011 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2011.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2011 > DONE\n",
            "INFO:root: > Year : 2012 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2012.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2012 > DONE\n",
            "INFO:root: > Year : 2013 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2013.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2013 > DONE\n",
            "INFO:root: > Year : 2014 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2014.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2014 > DONE\n",
            "INFO:root: > Year : 2015 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2015.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2015 > DONE\n",
            "INFO:root: > Year : 2016 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2016.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2016 > DONE\n",
            "INFO:root: > Year : 2017 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2017.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2017 > DONE\n",
            "INFO:root: > Year : 2018 > file found : <zipfile.ZipExtFile name='PrixCarburants_annuel_2018.xml' mode='r' compress_type=deflate>\n",
            "INFO:root: > Year : 2018 > DONE\n",
            "INFO:root: > File : tmp/pdv.csv > CLOSE\n",
            "INFO:root: > File : tmp/prix.csv > CLOSE\n",
            "INFO:root: > File : tmp/ouverture.csv > CLOSE\n",
            "INFO:root: > File : tmp/services.csv > CLOSE\n",
            "INFO:root: > File : tmp/fermeture.csv > CLOSE\n",
            "INFO:root: > File : tmp/rupture.csv > CLOSE\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\t\t>>> export_xml_to_csv execution time: 545.7057 secs. <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aceGfBLdMnf2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "FIN FEUILLE CONVERTION XML EN CSV\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}